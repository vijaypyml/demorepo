{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "Correlation Feature Selection evaluates subsets of features on the basis of the following hypothesis: \"Good feature subsets contain features highly correlated with the target, yet uncorrelated to each other\".\n",
    "\n",
    "**References**:\n",
    "\n",
    "M. Hall 1999, [Correlation-based Feature Selection for Machine Learning](http://www.cs.waikato.ac.nz/~mhall/thesis.pdf)\n",
    "\n",
    "Senliol, Baris, et al. \"Fast Correlation Based Filter (FCBF) with a different search strategy.\" Computer and Information Sciences.\n",
    "\n",
    "\n",
    "\n",
    "I will demonstrate how to select features based on correlation using 2 procedures. The first one is a brute force function that finds correlated features without any further insight. The second procedure finds groups of correlated features. Often, more than 2 features are correlated with each other. We can find groups of 3, 4 or more features that are correlated. By identifying these groups, we can then select from each group, which feature we want to keep, and which ones we want to remove.\n",
    "\n",
    "I will use the Paribas claims dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('Advertising.csv', nrows=50000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>radio1</th>\n",
       "      <th>Constant</th>\n",
       "      <th>Quase</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>37.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>45.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>41.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  radio  radio1  Constant  Quase  newspaper  sales\n",
       "0           1  230.1   37.8    37.8         1      1       69.2   22.1\n",
       "1           2   44.5   39.3    39.3         1      1       45.1   10.4\n",
       "2           3   17.2   45.9    45.9         1      1       69.3    9.3\n",
       "3           4  151.5   41.3    41.3         1      1       58.5   18.5\n",
       "4           5  180.8   10.8    10.8         1      1       58.4   12.9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess whether they are correlated with other features\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 3), (40, 3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['sales','radio1','Constant','Quase', 'Unnamed: 0'], axis=1),\n",
    "    data['sales'],\n",
    "    test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a28072c880>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x792 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise correlated features\n",
    "# I will build the correlation matrix, which examines the \n",
    "# correlation of all features (for all possible feature combinations)\n",
    "# and then visualise the correlation matrix using seaborn\n",
    "\n",
    "corrmat = X_train.corr()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(11,11)\n",
    "sns.heatmap(corrmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, the red squares correspond to highly correlated features (>0.8). We can see that there are quite a few. The diagonal represents the correlation of a feature with itself, therefore the value is 1.\n",
    "\n",
    "### Brute force approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the following function we can select highly correlated features\n",
    "# it will remove the first feature that is correlated with anything else\n",
    "# without any other insight.\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features = correlation(X_train, 0.8)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 55 features are highly correlated with other features in the training set. Very likely, by removing these correlated features, the performance of your machine learning models will drop very little, if at all. We can go ahead and drop the features like we have done in previous lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 3), (40, 3))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing correlated columns we reduced the feature space from 112 numerical columns to 57, almost half of the original set.\n",
    "\n",
    "### Second approach\n",
    "\n",
    "The second approach looks to identify groups of highly correlated features. And then, we can make further investigation within these groups to decide which feature we keep and which one we remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('Advertising.csv', nrows=50000)\n",
    "\n",
    "# select numerical variables\n",
    "data = data[numerical_vars]\n",
    "\n",
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['sales','radio1','Constant','Quase', 'Unnamed: 0'], axis=1),\n",
    "    data['sales'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature1, feature2, corr]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a dataframe with the correlation between features\n",
    "# remember that the absolute value of the correlation\n",
    "# coefficient is important and not the sign\n",
    "\n",
    "corrmat = X_train.corr()\n",
    "corrmat = corrmat.abs().unstack() # absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.8]\n",
    "corrmat = corrmat[corrmat < 1]\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 0 correlated groups\n",
      "out of 3 total features\n"
     ]
    }
   ],
   "source": [
    "# find groups of correlated features\n",
    "\n",
    "grouped_feature_ls = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corrmat.feature1.unique():\n",
    "    if feature not in grouped_feature_ls:\n",
    "\n",
    "        # find all features correlated to a single feature\n",
    "        correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "        grouped_feature_ls = grouped_feature_ls + list(\n",
    "            correlated_block.feature2.unique()) + [feature]\n",
    "\n",
    "        # append the block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('found {} correlated groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features'.format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now we can visualise each group. We see that some groups contain\n",
    "# only 2 correlated features, some other groups present several features \n",
    "# that are correlated among themselves.\n",
    "\n",
    "for group in correlated_groups:\n",
    "    print(group)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-63bd5b0fa818>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# let's for example select group 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrelated_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# we can now investigate further features within one group.\n",
    "# let's for example select group 3\n",
    "\n",
    "group = correlated_groups[0]\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'v76'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'v76'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-5fd4e984f3dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'v17'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'v76'"
     ]
    }
   ],
   "source": [
    "# we could select the features with less missing data\n",
    "# like this:\n",
    "\n",
    "for feature in list(group.feature2.unique())+['v17']:\n",
    "    print(X_train[feature].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features show similar number of missing data in this case.\n",
    "\n",
    "Alternatively, we could build a machine learning algorithm using all the features from the above list, and select the more predictive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=200, random_state=39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features = list(group.feature2.unique())+['v17']\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "rf.fit(X_train[features].fillna(0), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v48</td>\n",
       "      <td>0.173981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v93</td>\n",
       "      <td>0.154484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>v101</td>\n",
       "      <td>0.129764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v64</td>\n",
       "      <td>0.118110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>v17</td>\n",
       "      <td>0.117571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v106</td>\n",
       "      <td>0.113958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v76</td>\n",
       "      <td>0.108071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v44</td>\n",
       "      <td>0.084062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "2     v48    0.173981\n",
       "3     v93    0.154484\n",
       "6    v101    0.129764\n",
       "1     v64    0.118110\n",
       "7     v17    0.117571\n",
       "4    v106    0.113958\n",
       "0     v76    0.108071\n",
       "5     v44    0.084062"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get the feature importance attributed by the \n",
    "# random forest model (more on this in coming lectures)\n",
    "\n",
    "importance = pd.concat(\n",
    "    [pd.Series(features),\n",
    "     pd.Series(rf.feature_importances_)], axis=1)\n",
    "\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, feature v48 shows the higher importance according to random forests. Then, I would select v48, and remove all the remaining features from this group from the dataset.\n",
    "\n",
    "**Note**\n",
    "\n",
    "None of the 2 procedures for removing correlated features are perfect, and some correlated features may escape the loops of code. So it might be worthwhile to check that after removing the correlated features, there are no correlated features left in the dataset. If there are, repeat the procedure to remove the remaining ones.\n",
    "\n",
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
